{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b10914c9",
   "metadata": {},
   "source": [
    "# Notebook para Análisis de Precios de Toyota Corolla\n",
    "\n",
    "## Configuración y Carga de Datos\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8ea972",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mlflow\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import os\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f1d530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración de MLflow\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "mlflow.set_experiment(\"toyota_parcial\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490c291f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar dataset\n",
    "df = pd.read_csv(\n",
    "    \"https://raw.githubusercontent.com/dodobeatle/dataeng-datos/refs/heads/main/ToyotaCorolla.csv\",\n",
    "    encoding=\"utf8\",\n",
    "    engine=\"python\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7b46f3",
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "source": [
    "## Limpieza de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfecb7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corregir la variable Doors y eliminar observaciones incorrectas\n",
    "print(\"\\nDistribución original de Doors:\")\n",
    "print(df['Doors'].value_counts())\n",
    "\n",
    "# Eliminar coches con 2 puertas (observaciones probablemente erróneas)\n",
    "df = df[df['Doors'] != 2]\n",
    "\n",
    "# Corregir coches con 4 puertas (4 laterales → 5 contando el maletero)\n",
    "df.loc[df['Doors'] == 4, 'Doors'] = 5\n",
    "\n",
    "print(\"\\nDistribución corregida de Doors:\")\n",
    "print(df['Doors'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d251220",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Exploración de Datos (EDA)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679bf1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensiones del dataset\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6627666c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Información general\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d6ad49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estadísticas descriptivas\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ded114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de columnas\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c226c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificación de valores nulos\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2b872c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análisis de variables categóricas\n",
    "sns.countplot(data=df, x=\"Fuel_Type\", palette=\"pastel\")\n",
    "plt.title(\"Distribución de Fuel_Type\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6699b333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Búsqueda de duplicados\n",
    "def find_duplicates(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Identifica filas duplicadas completas en el DataFrame.\n",
    "    \"\"\"\n",
    "    mask = df.duplicated(keep='first')\n",
    "    duplicates = df[mask].copy()\n",
    "    return duplicates\n",
    "\n",
    "duplicates = find_duplicates(df)\n",
    "print(f\"Número de filas duplicadas: {len(duplicates)}\")\n",
    "if len(duplicates) > 0:\n",
    "    print(\"Filas duplicadas:\")\n",
    "    print(duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad2aa57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generamos matriz de correlación para el análisis exploratorio\n",
    "corr = df.select_dtypes(include=['number']).corr()\n",
    "\n",
    "# Top correlaciones con Price\n",
    "top_vars = (corr['Price']\n",
    "            .abs()\n",
    "            .sort_values(ascending=False)\n",
    "            .head(11))   # Price + 10 más altas\n",
    "\n",
    "print(\"Variables más correlacionadas con Price:\")\n",
    "print(top_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c63576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización de correlaciones principales\n",
    "top_vars_idx = top_vars.index\n",
    "sub_corr = corr.loc[top_vars_idx, top_vars_idx]\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(\n",
    "    sub_corr,\n",
    "    cmap=\"vlag\",\n",
    "    annot=True,\n",
    "    fmt=\".2f\",\n",
    "    linewidths=.5,\n",
    "    center=0\n",
    ")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.title(\"Top 10 correlaciones con Price\", fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1c514d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detección de outliers\n",
    "def detect_outliers(df):\n",
    "    cols = df.select_dtypes(include=np.number).columns\n",
    "    outliers = pd.DataFrame(columns=['Feature', 'Number of Outliers'])\n",
    "    \n",
    "    for column in cols:\n",
    "        q1 = df[column].quantile(0.25)\n",
    "        q3 = df[column].quantile(0.75)\n",
    "        iqr = q3 - q1\n",
    "        fence_low = q1 - (1.5*iqr)\n",
    "        fence_high = q3 + (1.5*iqr)\n",
    "        outliers_count = df.loc[(df[column] < fence_low) | (df[column] > fence_high)].shape[0]\n",
    "        \n",
    "        outliers = pd.concat([outliers, pd.DataFrame({\n",
    "            'Feature': [column], \n",
    "            'Number of Outliers': [outliers_count]\n",
    "        })], ignore_index=True)\n",
    "    \n",
    "    return outliers.sort_values('Number of Outliers', ascending=False)\n",
    "\n",
    "outlier_analysis = detect_outliers(df)\n",
    "outlier_analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f468c0",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Preprocesamiento y Feature Engineering\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d0afd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar X (predictores) e y (variable objetivo)\n",
    "X = df.drop(\"Price\", axis=1)\n",
    "y = df[\"Price\"]\n",
    "\n",
    "# Eliminar columnas no relevantes para el modelo\n",
    "X = df.drop([\"Price\", \"Model\", \"Cylinders\", \"Id\", \"Radio_cassette\", \"BOVAG_Guarantee\",\n",
    "             \"Backseat_Divider\", \"Mfg_Month\",\"Mfg_Year\", \"Automatic\", \"Central_Lock\",\n",
    "             \"Met_Color\", \"Mfr_Guarantee\", \"Guarantee_Period\", \"Gears\", \"Radio\", \"Power_Steering\",\n",
    "             \"Metallic_Rim\", \"Tow_Bar\", \"Sport_Model\"], axis=1)\n",
    "\n",
    "print(\"Variables conservadas:\")\n",
    "print(X.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cecf2de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering\n",
    "# Combinar airbags en una sola variable\n",
    "X[\"Airbag_Count\"] = df[\"Airbag_1\"].fillna(0) + df[\"Airbag_2\"].fillna(0)\n",
    "X.drop([\"Airbag_1\", \"Airbag_2\"], axis=1, inplace=True)\n",
    "\n",
    "# Codificación de variables categóricas\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "# Forzar tipos numéricos\n",
    "X = X.apply(pd.to_numeric, errors='coerce')\n",
    "y = pd.to_numeric(y, errors='coerce')\n",
    "\n",
    "# Eliminar filas con NaNs\n",
    "combined = pd.concat([X, y], axis=1).dropna()\n",
    "X = combined.drop(\"Price\", axis=1)\n",
    "y = combined[\"Price\"]\n",
    "\n",
    "# Convertir a float y agregar constante para OLS\n",
    "X = X.astype(float)\n",
    "y = y.astype(float)\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# División train-test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.4, random_state=1\n",
    ")\n",
    "\n",
    "print(f\"Dimensiones de X_train: {X_train.shape}, X_test: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f9522b",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "## Selección de Características con Lasso\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42eb4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lasso Regression\n",
    "from sklearn.linear_model import LassoCV\n",
    "\n",
    "# Quitar constante para Lasso\n",
    "X_train_lasso = X_train.drop(\"const\", axis=1)\n",
    "X_test_lasso = X_test.drop(\"const\", axis=1)\n",
    "\n",
    "# Entrenamiento con validación cruzada\n",
    "lasso = LassoCV(cv=5, random_state=1)\n",
    "lasso.fit(X_train_lasso, y_train)\n",
    "\n",
    "# Predicciones y métricas\n",
    "y_pred_lasso = lasso.predict(X_test_lasso)\n",
    "rmse_lasso = np.sqrt(mean_squared_error(y_test, y_pred_lasso))\n",
    "mae_lasso = mean_absolute_error(y_test, y_pred_lasso)\n",
    "r2_lasso = r2_score(y_test, y_pred_lasso)\n",
    "\n",
    "print(f\"Alpha óptimo: {lasso.alpha_:.6f}\")\n",
    "print(f\"RMSE: {rmse_lasso:.2f}\")\n",
    "print(f\"MAE: {mae_lasso:.2f}\")\n",
    "print(f\"R²: {r2_lasso:.4f}\")\n",
    "\n",
    "# Variables seleccionadas\n",
    "lasso_features = X_train_lasso.columns[lasso.coef_ != 0]\n",
    "print(f\"\\nFeatures seleccionadas por Lasso ({len(lasso_features)}/{X_train_lasso.shape[1]}):\")\n",
    "print(lasso_features.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67b2ba9",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Reducción de Dimensionalidad con PCA\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d8e2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Estandarización\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_lasso)\n",
    "X_test_scaled = scaler.transform(X_test_lasso)\n",
    "\n",
    "# PCA\n",
    "pca = PCA(n_components=0.95, random_state=1)\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "print(f\"Número de componentes PCA (95% varianza): {pca.n_components_}\")\n",
    "\n",
    "# Modelo con PCA\n",
    "lasso_pca = LassoCV(cv=5, random_state=1)\n",
    "lasso_pca.fit(X_train_pca, y_train)\n",
    "y_pred_pca = lasso_pca.predict(X_test_pca)\n",
    "\n",
    "# Evaluación\n",
    "rmse_pca = np.sqrt(mean_squared_error(y_test, y_pred_pca))\n",
    "r2_pca = r2_score(y_test, y_pred_pca)\n",
    "\n",
    "print(f\"RMSE: {rmse_pca:.2f}\")\n",
    "print(f\"R²: {r2_pca:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee2ee9c",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Modelo de Regresión Lineal (OLS)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0688f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name=\"ols_model_run\"):\n",
    "    # Ajuste OLS\n",
    "    model = sm.OLS(y_train, X_train)\n",
    "    results = model.fit()\n",
    "    \n",
    "    # Resumen del modelo\n",
    "    print(results.summary())\n",
    "    \n",
    "    # Predicción\n",
    "    y_pred = results.predict(X_test)\n",
    "    \n",
    "    # Métricas\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2_sklearn = r2_score(y_test, y_pred)\n",
    "    r2_sm = results.rsquared\n",
    "    adj_r2 = results.rsquared_adj\n",
    "    aic = results.aic\n",
    "    bic = results.bic\n",
    "    \n",
    "    print(f\"\\nMétricas de evaluación:\")\n",
    "    print(f\"RMSE: {rmse:.2f}\")\n",
    "    print(f\"MAE: {mae:.2f}\")\n",
    "    print(f\"R²: {r2_sklearn:.4f}\")\n",
    "    print(f\"R² ajustado: {adj_r2:.4f}\")\n",
    "    print(f\"AIC: {aic:.2f}\")\n",
    "    print(f\"BIC: {bic:.2f}\")\n",
    "    \n",
    "    # Registro en MLflow\n",
    "    mlflow.log_metric(\"rmse\", float(rmse))\n",
    "    mlflow.log_metric(\"mae\", float(mae))\n",
    "    mlflow.log_metric(\"r2_sklearn\", float(r2_sklearn))\n",
    "    mlflow.log_metric(\"r2_statsmodels\", float(r2_sm))\n",
    "    mlflow.log_metric(\"adj_r2\", float(adj_r2))\n",
    "    mlflow.log_metric(\"aic\", float(aic))\n",
    "    mlflow.log_metric(\"bic\", float(bic))\n",
    "    mlflow.log_metric(\"n_features\", int(X_train.shape[1]))\n",
    "    \n",
    "    # Carpeta para artefactos\n",
    "    os.makedirs(\"mlartifacts\", exist_ok=True)\n",
    "    \n",
    "    # Guardar artefactos\n",
    "    summary_path = os.path.join(\"mlartifacts\", \"ols_summary.txt\")\n",
    "    with open(summary_path, \"w\") as f:\n",
    "        f.write(results.summary().as_text())\n",
    "    mlflow.log_artifact(summary_path)\n",
    "    \n",
    "    model_pkl = os.path.join(\"mlartifacts\", \"ols_model.pkl\")\n",
    "    joblib.dump(results, model_pkl)\n",
    "    mlflow.log_artifact(model_pkl)\n",
    "    \n",
    "    features_path = os.path.join(\"mlartifacts\", \"features.txt\")\n",
    "    with open(features_path, \"w\") as f:\n",
    "        f.write(\"\\n\".join(X.columns))\n",
    "    mlflow.log_artifact(features_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa49e88a",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Análisis de Multicolinealidad\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d96f0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análisis VIF\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"feature\"] = X_train.columns\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(X_train.values, i) \n",
    "                  for i in range(X_train.shape[1])]\n",
    "    \n",
    "# Ordenar por VIF descendente\n",
    "vif_data = vif_data.sort_values(\"VIF\", ascending=False)\n",
    "\n",
    "print(\"Análisis de Factor de Inflación de Varianza (VIF):\")\n",
    "print(\"Un VIF > 10 indica alta multicolinealidad\")\n",
    "print(vif_data)\n",
    "\n",
    "# Guardar resultados\n",
    "vif_path = os.path.join(\"mlartifacts\", \"vif_report.csv\")\n",
    "vif_data.to_csv(vif_path, index=False)\n",
    "mlflow.log_artifact(vif_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8843fa",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Visualización de Resultados\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28596520",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot: Real vs. Predicho\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_test, y_pred, alpha=0.6, edgecolors='k')\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], '--r', lw=2)\n",
    "plt.xlabel(\"Precio Real\")\n",
    "plt.ylabel(\"Precio Predicho\")\n",
    "plt.title(\"Precio Real vs. Precio Predicho\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "\n",
    "real_vs_pred_path = os.path.join(\"mlartifacts\", \"actual_vs_predicted.png\")\n",
    "plt.savefig(real_vs_pred_path)\n",
    "mlflow.log_artifact(real_vs_pred_path)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66fb9d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análisis de residuos\n",
    "residuals = y_test - y_pred\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_pred, residuals, alpha=0.6, edgecolors='k')\n",
    "plt.axhline(y=0, color='r', linestyle='--')\n",
    "plt.xlabel(\"Precio Predicho\")\n",
    "plt.ylabel(\"Residuos\")\n",
    "plt.title(\"Gráfico de Residuos\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "\n",
    "residuals_path = os.path.join(\"mlartifacts\", \"residuals_plot.png\")\n",
    "plt.savefig(residuals_path)\n",
    "mlflow.log_artifact(residuals_path)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a959f7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histograma de residuos\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.hist(residuals, bins=30, alpha=0.7, edgecolor='k')\n",
    "plt.axvline(x=0, color='r', linestyle='--')\n",
    "plt.xlabel(\"Residuos\")\n",
    "plt.ylabel(\"Frecuencia\")\n",
    "plt.title(\"Distribución de Residuos\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6675e87",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Comparativa de Modelos\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5d08a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear tabla comparativa\n",
    "results_df = pd.DataFrame({\n",
    "    \"Modelo\": [\"OLS\", \"Lasso\", \"Lasso+PCA\"],\n",
    "    \"RMSE\": [rmse, rmse_lasso, rmse_pca],\n",
    "    \"MAE\": [mae, mae_lasso, mean_absolute_error(y_test, y_pred_pca)],\n",
    "    \"R²\": [r2_sklearn, r2_lasso, r2_pca],\n",
    "    \"Num. Features\": [X_train.shape[1], len(lasso_features), pca.n_components_]\n",
    "})\n",
    "\n",
    "print(\"Comparativa de modelos:\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9856573d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conclusiones\n",
    "print(\"\\nCONCLUSIONES:\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"• El modelo {results_df.loc[results_df['R²'].idxmax(), 'Modelo']} tiene el mejor R² ({results_df['R²'].max():.4f}).\")\n",
    "print(f\"• El modelo {results_df.loc[results_df['RMSE'].idxmin(), 'Modelo']} tiene el RMSE más bajo ({results_df['RMSE'].min():.2f}).\")\n",
    "print(f\"• Las variables más importantes para predecir el precio son:\")\n",
    "for feat, coef in sorted(zip(X_train.columns[1:], results.params[1:]), key=lambda x: abs(x[1]), reverse=True)[:5]:\n",
    "    print(f\"  - {feat}: {coef:.4f}\")\n",
    "print(\"-\" * 60)\n",
    "print(\"Modelo registrado con MLflow.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "toyota",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
